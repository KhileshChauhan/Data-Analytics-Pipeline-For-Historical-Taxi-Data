{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "## Import packages"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "from pyspark.sql import Row\nfrom pyspark.sql.types import FloatType, IntegerType\nfrom pyspark.sql.functions import col\nimport sys", "execution_count": 1, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "5d6fb591bb594962b07620fc7a2cd91e"}}, "metadata": {}}, {"output_type": "stream", "text": "Starting Spark application\n", "name": "stdout"}, {"output_type": "display_data", "data": {"text/plain": "<IPython.core.display.HTML object>", "text/html": "<table>\n<tr><th>ID</th><th>YARN Application ID</th><th>Kind</th><th>State</th><th>Spark UI</th><th>Driver log</th><th>Current session?</th></tr><tr><td>0</td><td>application_1543784618195_0001</td><td>pyspark</td><td>idle</td><td><a target=\"_blank\" href=\"http://ip-172-31-27-84.us-west-1.compute.internal:20888/proxy/application_1543784618195_0001/\">Link</a></td><td><a target=\"_blank\" href=\"http://ip-172-31-31-46.us-west-1.compute.internal:8042/node/containerlogs/container_1543784618195_0001_01_000001/livy\">Link</a></td><td>\u2714</td></tr></table>"}, "metadata": {}}, {"output_type": "stream", "text": "SparkSession available as 'spark'.\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Read file and extract a map of required columns"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "# datafile=\"s3n://nyc-tlc/trip data/green_tripdata_2018-06.csv\" # has area codes\ndatafile=\"s3n://nyc-tlc/trip data/yellow_tripdata_2015-07.csv\" # has lat/long data\nrdd = sc.textFile(datafile).map(lambda line: line.split(\",\")).filter(lambda line: len(line)>1)\ncol_names = rdd.take(1)[0]\ncolumn_map = {}\nuseful_columns = [\"pickup_longitude\", \"pickup_latitude\", \"dropoff_longitude\", \"dropoff_latitude\", \"pickup_datetime\", \"dropoff_datetime\", \"dolocationid\", \"pulocationid\", \"fare_amount\", \"trip_distance\", \"passenger_count\"]\n\nfor i, c in enumerate(col_names):\n    c = c.lower()\n    for u in useful_columns:\n        if c in u or u in c:\n            column_map[u] = i\n            \nprint(\"Found attributes - {}\".format(column_map.keys()))", "execution_count": 45, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "baf8904809b04e01b0716484de7b164c"}}, "metadata": {}}, {"output_type": "stream", "text": "Found attributes - ['trip_distance', 'pickup_datetime', 'fare_amount', 'pickup_longitude', 'dropoff_longitude', 'passenger_count', 'dropoff_datetime', 'pickup_latitude', 'dropoff_latitude']", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Sanity check - all the required columns should be present"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "required_columns = [\"pickup_datetime\", \"dropoff_datetime\", \"fare_amount\", \"trip_distance\", \"passenger_count\"]\nfor c in required_columns:\n    if c not in column_map:\n        print(\"Required column {} not found in the data. Exiting.\".format(c))\n        sys.exit(1)\n        \nexit = False\nfor c in [\"pickup_longitude\", \"pickup_latitude\", \"dropoff_longitude\", \"dropoff_latitude\"]:\n    if c not in column_map:\n        exit = True\n        \nif exit:\n    for c in [\"dolocationid\", \"pulocationid\"]:\n        if c not in column_map:\n            print(\"Required columns for location not found in the data. Exiting.\".format(c))\n            sys.exit(1)\n            \nprint(\"Sanity check complete. Data can be preprocessed.\")\n", "execution_count": 46, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "529e79b7df0b4242b24c1fcf02d75d1e"}}, "metadata": {}}, {"output_type": "stream", "text": "Sanity check complete. Data can be preprocessed.", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Display the RDDs"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "rdd.take(10)\nrdd.take(10)", "execution_count": 47, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "c8927e322fcf4c25bf83415e6c9abf16"}}, "metadata": {}}, {"output_type": "stream", "text": "[[u'VendorID', u'tpep_pickup_datetime', u'tpep_dropoff_datetime', u'passenger_count', u'trip_distance', u'pickup_longitude', u'pickup_latitude', u'RatecodeID', u'store_and_fwd_flag', u'dropoff_longitude', u'dropoff_latitude', u'payment_type', u'fare_amount', u'extra', u'mta_tax', u'tip_amount', u'tolls_amount', u'improvement_surcharge', u'total_amount'], [u'1', u'2015-07-01 00:00:00', u'2015-07-01 00:15:26', u'1', u'3.50', u'-73.994155883789063', u'40.751125335693359', u'1', u'N', u'-73.976821899414063', u'40.788566589355469', u'2', u'14', u'0.5', u'0.5', u'0', u'0', u'0.3', u'15.3'], [u'1', u'2015-07-01 00:00:00', u'2015-07-01 00:22:22', u'1', u'3.90', u'-73.984657287597656', u'40.768486022949219', u'1', u'N', u'-74.000129699707031', u'40.734897613525391', u'2', u'17', u'0.5', u'0.5', u'0', u'0', u'0.3', u'18.3'], [u'1', u'2015-07-01 00:00:00', u'2015-07-01 00:07:42', u'1', u'2.30', u'-73.978889465332031', u'40.762287139892578', u'1', u'N', u'-74.004219055175781', u'40.752532958984375', u'2', u'9', u'0.5', u'0.5', u'0', u'0', u'0.3', u'10.3'], [u'1', u'2015-07-01 00:00:00', u'2015-07-01 00:39:37', u'1', u'9.20', u'-73.992790222167969', u'40.742759704589844', u'1', u'N', u'-73.971511840820313', u'40.637153625488281', u'1', u'33', u'0.5', u'0.5', u'8.55', u'0', u'0.3', u'42.85'], [u'1', u'2015-07-01 00:00:00', u'2015-07-01 00:05:34', u'1', u'1.10', u'-73.912429809570313', u'40.769809722900391', u'1', u'N', u'-73.920333862304688', u'40.757442474365234', u'1', u'6', u'0.5', u'0.5', u'2', u'0', u'0.3', u'9.3'], [u'1', u'2015-07-01 00:00:00', u'2015-07-01 00:06:46', u'2', u'1.00', u'-73.959159851074219', u'40.773429870605469', u'1', u'N', u'-73.969352722167969', u'40.769245147705078', u'2', u'6.5', u'0.5', u'0.5', u'0', u'0', u'0.3', u'7.8'], [u'2', u'2015-07-01 00:00:00', u'2015-07-01 00:36:57', u'2', u'19.12', u'-73.789459228515625', u'40.647258758544922', u'1', u'N', u'-73.974937438964844', u'40.649429321289063', u'1', u'54.5', u'0.5', u'0.5', u'13.95', u'0', u'0.3', u'69.75'], [u'2', u'2015-07-01 00:00:00', u'2015-07-01 06:30:15', u'1', u'.00', u'0', u'0', u'1', u'N', u'-73.9859619140625', u'40.766399383544922', u'2', u'2.5', u'0', u'0.5', u'0', u'0', u'0', u'3'], [u'2', u'2015-07-01 00:00:00', u'2015-07-01 11:27:07', u'1', u'2.58', u'-73.998931884765625', u'40.744678497314453', u'1', u'N', u'-73.982215881347656', u'40.776885986328125', u'1', u'15', u'0.3', u'0.5', u'1', u'0', u'0.3', u'17.1']]", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Remove the header from RDDs"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "header = rdd.first()\nrdd = rdd.filter(lambda line: line != header)", "execution_count": 48, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "6b2d72daad9b401da62ca8a5b7d8e8fd"}}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Display RDDs"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "rdd.take(10)", "execution_count": 49, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "a186e565c3e54dec91cc4b0b87ab2f85"}}, "metadata": {}}, {"output_type": "stream", "text": "[[u'1', u'2015-07-01 00:00:00', u'2015-07-01 00:15:26', u'1', u'3.50', u'-73.994155883789063', u'40.751125335693359', u'1', u'N', u'-73.976821899414063', u'40.788566589355469', u'2', u'14', u'0.5', u'0.5', u'0', u'0', u'0.3', u'15.3'], [u'1', u'2015-07-01 00:00:00', u'2015-07-01 00:22:22', u'1', u'3.90', u'-73.984657287597656', u'40.768486022949219', u'1', u'N', u'-74.000129699707031', u'40.734897613525391', u'2', u'17', u'0.5', u'0.5', u'0', u'0', u'0.3', u'18.3'], [u'1', u'2015-07-01 00:00:00', u'2015-07-01 00:07:42', u'1', u'2.30', u'-73.978889465332031', u'40.762287139892578', u'1', u'N', u'-74.004219055175781', u'40.752532958984375', u'2', u'9', u'0.5', u'0.5', u'0', u'0', u'0.3', u'10.3'], [u'1', u'2015-07-01 00:00:00', u'2015-07-01 00:39:37', u'1', u'9.20', u'-73.992790222167969', u'40.742759704589844', u'1', u'N', u'-73.971511840820313', u'40.637153625488281', u'1', u'33', u'0.5', u'0.5', u'8.55', u'0', u'0.3', u'42.85'], [u'1', u'2015-07-01 00:00:00', u'2015-07-01 00:05:34', u'1', u'1.10', u'-73.912429809570313', u'40.769809722900391', u'1', u'N', u'-73.920333862304688', u'40.757442474365234', u'1', u'6', u'0.5', u'0.5', u'2', u'0', u'0.3', u'9.3'], [u'1', u'2015-07-01 00:00:00', u'2015-07-01 00:06:46', u'2', u'1.00', u'-73.959159851074219', u'40.773429870605469', u'1', u'N', u'-73.969352722167969', u'40.769245147705078', u'2', u'6.5', u'0.5', u'0.5', u'0', u'0', u'0.3', u'7.8'], [u'2', u'2015-07-01 00:00:00', u'2015-07-01 00:36:57', u'2', u'19.12', u'-73.789459228515625', u'40.647258758544922', u'1', u'N', u'-73.974937438964844', u'40.649429321289063', u'1', u'54.5', u'0.5', u'0.5', u'13.95', u'0', u'0.3', u'69.75'], [u'2', u'2015-07-01 00:00:00', u'2015-07-01 06:30:15', u'1', u'.00', u'0', u'0', u'1', u'N', u'-73.9859619140625', u'40.766399383544922', u'2', u'2.5', u'0', u'0.5', u'0', u'0', u'0', u'3'], [u'2', u'2015-07-01 00:00:00', u'2015-07-01 11:27:07', u'1', u'2.58', u'-73.998931884765625', u'40.744678497314453', u'1', u'N', u'-73.982215881347656', u'40.776885986328125', u'1', u'15', u'0.3', u'0.5', u'1', u'0', u'0.3', u'17.1'], [u'2', u'2015-07-01 00:00:00', u'2015-07-01 00:00:00', u'1', u'1.07', u'-73.99383544921875', u'40.735431671142578', u'1', u'N', u'-74.0078125', u'40.731830596923828', u'1', u'7.5', u'0', u'0.5', u'1.66', u'0', u'0.3', u'9.96']]", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Create Dataframes from RDDs - cast them to proper type"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def createDF(rdd, column_map):\n    if 'dolocationid' in column_map:\n        df = rdd.map(lambda line: Row(pulocationid=line[column_map['pulocationid']], \n                              dolocationid=line[column_map['dolocationid']], \n                              pickup_datetime=line[column_map['pickup_datetime']], \n                              dropoff_datetime=line[column_map['dropoff_datetime']],\n                              trip_distance=line[column_map['trip_distance']], \n                              fare_amount=line[column_map['fare_amount']], \n                              passenger_count=line[column_map['passenger_count']])).toDF()\n        \n        df = df.withColumn(\"dolocationid\", df[\"dolocationid\"].cast(IntegerType()))\n        df = df.withColumn(\"fare_amount\",df[\"fare_amount\"].cast(FloatType()))\n        df = df.withColumn(\"passenger_count\", df[\"passenger_count\"].cast(IntegerType()))\n        df = df.withColumn(\"pulocationid\", df[\"pulocationid\"].cast(IntegerType()))\n        df = df.withColumn(\"trip_distance\", df[\"trip_distance\"].cast(FloatType()))\n\n    else:\n        df = rdd.map(lambda line: Row(pickup_longitude=line[column_map['pickup_longitude']], \n                              pickup_latitude=line[column_map['pickup_latitude']], \n                              dropoff_longitude=line[column_map['dropoff_longitude']], \n                              dropoff_latitude=line[column_map['dropoff_latitude']], \n                              pickup_datetime=line[column_map['pickup_datetime']], \n                              dropoff_datetime=line[column_map['dropoff_datetime']], \n                              trip_distance=line[column_map['trip_distance']], \n                              fare_amount=line[column_map['fare_amount']], \n                              passenger_count=line[column_map['passenger_count']])).toDF()\n        df = df.withColumn(\"dropoff_longitude\", df[\"dropoff_longitude\"].cast(FloatType()))\n        df = df.withColumn(\"dropoff_latitude\", df[\"dropoff_latitude\"].cast(FloatType()))\n        df = df.withColumn(\"fare_amount\",df[\"fare_amount\"].cast(FloatType()))\n        df = df.withColumn(\"passenger_count\", df[\"passenger_count\"].cast(IntegerType()))\n        df = df.withColumn(\"pickup_longitude\", df[\"pickup_longitude\"].cast(FloatType()))\n        df = df.withColumn(\"pickup_latitude\", df[\"pickup_latitude\"].cast(FloatType()))\n        df = df.withColumn(\"trip_distance\", df[\"trip_distance\"].cast(FloatType()))\n    return df", "execution_count": 50, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "a52690f72d05480ab73864f06d4776d7"}}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Feature engineering - add zipcode"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def addZipCode(df, column_map):\n    if 'dolocationid' in column_map:\n        from itertools import chain\n        from pyspark.sql.functions import create_map, lit\n        # this map has been generated separately, stored here for ease of access\n        zipcodeMap = {1: 7114, 2: 11430, 3: 10469, 4: 10009, 5: 10309, 6: 10305, 7: 11101, 8: 11105, 9: 11358, 10: 11434, 11: 11214, 12: 10280, 13: 10280, 14: 11209, 15: 11359, 16: 11361, 17: 10506, 18: 10458, 19: 11426, 20: 14813, 21: 11206, 22: 11207, 23: 10314, 24: 12913, 25: 11201, 26: 11212, 27: 11697, 28: 11435, 29: 11235, 30: 11693, 31: 10453, 32: 10462, 33: 11201, 34: 11251, 35: 11212, 36: 11221, 37: 11237, 38: 11411, 39: 11234, 40: 11231, 41: 10026, 42: 10027, 43: 10019, 44: 10309, 45: 10013, 46: 10464, 47: 10457, 48: 10001, 49: 11205, 50: 10002, 51: 10475, 52: 11201, 53: 11356, 54: 11231, 55: 11224, 56: 11368, 57: 11368, 58: 10465, 59: 10457, 60: 10459, 61: 11238, 62: 11205, 63: 11208, 64: 11363, 65: 11201, 66: 11201, 67: 11228, 68: 10019, 69: 10451, 70: 11369, 71: 11203, 72: 11236, 73: 11355, 74: 10035, 75: 10029, 76: 10003, 77: 11207, 78: 10457, 79: 10211, 80: 11211, 81: 10466, 82: 11373, 83: 11378, 84: 10308, 85: 11226, 86: 11691, 87: 10005, 88: 10006, 89: 11226, 90: 10010, 91: 11239, 92: 11355, 93: 11368, 94: 10468, 95: 11375, 96: 11385, 97: 11205, 98: 11365, 99: 10312, 100: 10018, 101: 11004, 102: 11385, 103: 10012, 104: 10012, 105: 10012, 106: 11215, 107: 10016, 108: 11223, 109: 10308, 110: 10306, 111: 11232, 112: 11222, 113: 10012, 114: 10013, 115: 10301, 116: 10031, 117: 11692, 118: 10314, 119: 10452, 120: 10034, 121: 11366, 122: 11423, 123: 11229, 124: 11414, 125: 10006, 126: 10474, 127: 10034, 128: 10031, 129: 11372, 130: 11412, 131: 11423, 132: 11430, 133: 11218, 134: 11415, 135: 11367, 136: 10468, 137: 10016, 138: 11371, 139: 11413, 140: 10021, 141: 10065, 142: 10023, 143: 10024, 144: 10013, 145: 11101, 146: 11101, 147: 10459, 148: 10009, 149: 11201, 150: 11235, 151: 10025, 152: 10027, 153: 10463, 154: 11234, 155: 11234, 156: 10303, 157: 11378, 158: 10014, 159: 10456, 160: 11379, 161: 10018, 162: 10022, 163: 10018, 164: 10017, 165: 11230, 166: 10027, 167: 10456, 168: 10451, 169: 10453, 170: 10010, 171: 11354, 172: 10306, 173: 11368, 174: 10467, 175: 11364, 176: 10306, 177: 11233, 178: 11230, 179: 11103, 180: 11416, 181: 11215, 182: 10462, 183: 10461, 184: 10461, 185: 10461, 186: 10016, 187: 10302, 188: 11225, 189: 11238, 190: 11215, 191: 11427, 192: 11355, 193: 11101, 194: 10035, 195: 11231, 196: 11374, 197: 11418, 198: 11385, 199: 11370, 200: 10471, 201: 11694, 202: 10044, 203: 11422, 204: 10309, 205: 11412, 206: 11378, 207: 11370, 208: 10469, 209: 10013, 210: 11235, 211: 10013, 212: 10472, 213: 10472, 214: 10305, 215: 11435, 216: 11420, 217: 11221, 218: 11413, 219: 11413, 220: 10463, 221: 10304, 222: 11239, 223: 11105, 224: 10009, 225: 11205, 226: 11104, 227: 11211, 228: 11232, 229: 10022, 230: 10036, 231: 10007, 232: 10002, 233: 10022, 234: 10003, 235: 10453, 236: 10021, 237: 10028, 238: 10044, 239: 10065, 240: 10463, 241: 10463, 242: 10461, 243: 10032, 244: 10034, 245: 10310, 246: 10036, 247: 10451, 248: 10460, 249: 10014, 250: 10462, 251: 10314, 252: 11357, 253: 11357, 254: 10467, 255: 10467, 256: 10467, 257: 11215, 258: 11421, 259: 10470, 260: 11377, 261: 10048, 262: 10028, 263: 10028, 264: '', 265: ''}\n        mapping_expr = create_map([lit(x) for x in chain(*zipcodeMap.items())])\n        df = df.withColumn(\"dropoff_zipcode\", mapping_expr[df[\"dolocationid\"]])\n        df = df.withColumn(\"pickup_zipcode\", mapping_expr[df[\"pulocationid\"]])\n        df = df.drop(\"dolocationid\", \"pulocationid\")\n    else:\n        from uszipcode import SearchEngine\n        from uszipcode import Zipcode\n        from pyspark.sql.functions import udf, array\n        import numpy as np\n\n        search = SearchEngine(simple_zipcode=True)\n        def get_zip_code(latitude,longitude):\n            try:\n                search = SearchEngine(simple_zipcode=True)\n                result = search.by_coordinates(latitude, longitude, radius=5, returns=1)\n                return result[0].zipcode\n            except ValueError as e:\n                return 10001\n\n        for index, row in df.iterrows():\n            lat = row['pickup_latitude']\n            lng = row['pickup_longitude']\n            zipcode = get_zip_code(lat,lng)\n            df.at[index,'zipcode'] = zipcode.zipcode\n    return df", "execution_count": 51, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "66e89c45ca794863a49bf8308c9ddd6a"}}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Remove NaN values"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def remove_nan_values(df):\n    num_columns = set(['dolocationid', 'fare_amount', 'passenger_count', 'pulocationid', 'trip_distance', 'pickup_latitude', 'pickup_longitude', 'dropoff_latitude', 'dropoff_longitude'])\n    for column in df.columns:\n        df = df.filter(col(column).isNotNull())\n        if column in num_columns:\n            df = df.filter(col(column) > 0.0)\n            print str(column)+ \"-->\" + str(df.count())\n    return df", "execution_count": 52, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "16d90a9709c840ad9517d9161b832d97"}}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Remove invalid latitude/longitude"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def remove_invalid_lat_long(df):\n    max_lat = 40.917577\n    min_lat = 40.477399 \n    max_long = -73.700272 \n    min_long = -74.259090\n    loc_cols = [\"pickup_longitude\", \"pickup_latitude\", \"dropoff_longitude\", \"dropoff_latitude\"]\n    print loc_cols\n    lat_cols = []\n    long_cols = []\n    for column in loc_cols:\n        if \"latitude\" in column.lower():\n            lat_cols.append(column)\n        elif \"longitude\" in column.lower():\n            long_cols.append(column)\n#     print lat_cols\n#     print long_cols\n            \n    for column in lat_cols:\n        df = df.filter(col(column).between(min_lat, max_lat))\n#         print \"lat : \"+ str(column) + \"-->\" + str(df.count())\n#         print (\"lat : {} ---> {}\".format(column, df.count()))\n    for column in long_cols:\n        df = df.filter(col(column).between(min_long, max_long))\n#         print (\"long : {} ---> {}\".format(column, df.count()))\n    return df", "execution_count": 53, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "085dbf408c504743bb37e7dc46f97ca3"}}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Remove trips with invalid fare"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "def remove_invalid_fare_trips(df):\n    df = df.filter(col('fare_amount') >= 2.5)\n    return df", "execution_count": 54, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "0270b46265de47d88e96db8de833cc47"}}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Handler function date preprocessing"}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "nPartitions = 2 # set this to the number of workers you have\ndef handler(rdd, column_map):\n    df1 = createDF(rdd, column_map)\n    df2 = addZipCode(df1, column_map)\n    df3 = remove_nan_values(df2)\n    if \"pickup_longitude\" in column_map:\n        df3 = remove_invalid_lat_long(df3)\n    df4 = remove_invalid_fare_trips(df3)\n    df4.write.save(\"s3n://dic-taxi-fare-prediction/data\", format='csv', header=True)\n#     newRdd = df3.rdd.map(list)\n#     newRdd.saveAsTextFile(\"s3n://dic-taxi-fare-prediction/data\")\n# sc.parallelize(rdd.collect(), nPartitions).map(lambda element: handler(element))\n# newRdd = handler(rdd)\nhandler(rdd, column_map)", "execution_count": 55, "outputs": [{"output_type": "display_data", "data": {"text/plain": "VBox()", "application/vnd.jupyter.widget-view+json": {"version_major": 2, "version_minor": 0, "model_id": "57feac60f9fb45e992cb8602c57e6c6a"}}, "metadata": {}}, {"output_type": "stream", "text": "'DataFrame' object has no attribute 'iterrows'\nTraceback (most recent call last):\n  File \"<stdin>\", line 4, in handler\n  File \"<stdin>\", line 26, in addZipCode\n  File \"/usr/lib/spark/python/lib/pyspark.zip/pyspark/sql/dataframe.py\", line 1182, in __getattr__\n    \"'%s' object has no attribute '%s'\" % (self.__class__.__name__, name))\nAttributeError: 'DataFrame' object has no attribute 'iterrows'\n\n", "name": "stderr"}]}, {"metadata": {"trusted": true}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "pysparkkernel", "display_name": "PySpark", "language": ""}, "language_info": {"name": "pyspark", "mimetype": "text/x-python", "codemirror_mode": {"name": "python", "version": 2}, "pygments_lexer": "python2"}}, "nbformat": 4, "nbformat_minor": 2}